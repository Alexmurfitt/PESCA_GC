import os
import csv
from bs4 import BeautifulSoup

# Carpeta donde est√°n los HTML guardados
input_dir = "fishbase_species"
output_csv = "fishbase_data.csv"
log_csv = "fishbase_scraper_log.csv"  # Donde tenemos nombres comunes + cient√≠ficos + URL

# Leer el log para mapear nombre com√∫n <-> cient√≠fico <-> URL
species_info = {}
with open(log_csv, mode="r", encoding="utf-8") as f:
    reader = csv.DictReader(f)
    for row in reader:
        common = row["Nombre com√∫n"]
        scientific = row["Nombre cient√≠fico"]
        url = row["URL"]
        filename = os.path.basename(row["Archivo HTML"])
        species_info[filename] = {
            "Nombre com√∫n": common,
            "Nombre cient√≠fico": scientific,
            "URL": url
        }

# Cabeceras del CSV final
headers = ["Nombre com√∫n", "Nombre cient√≠fico", "Longitud m√°xima", "Peso m√°ximo", "Distribuci√≥n", "Alimentaci√≥n", "IUCN", "URL"]

# Funci√≥n de extracci√≥n desde HTML
def extract_info_from_html(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f, "lxml")

    def get_text(label):
        row = soup.find("td", string=label)
        if row:
            value = row.find_next_sibling("td")
            return value.get_text(strip=True) if value else ""
        return ""

    return {
        "Longitud m√°xima": get_text("Max length :"),
        "Peso m√°ximo": get_text("Max. weight :"),
        "Distribuci√≥n": get_text("Distribution"),
        "Alimentaci√≥n": get_text("Feeding"),
        "IUCN": get_text("IUCN Red List Status")
    }

# Escritura del CSV final
with open(output_csv, mode="w", newline="", encoding="utf-8") as f_out:
    writer = csv.DictWriter(f_out, fieldnames=headers)
    writer.writeheader()

    for filename in os.listdir(input_dir):
        if not filename.endswith(".html"):
            continue
        filepath = os.path.join(input_dir, filename)
        base_info = species_info.get(filename, {})
        extracted = extract_info_from_html(filepath)
        row = {
            **base_info,
            **extracted
        }
        writer.writerow(row)
        print(f"‚úÖ Procesado: {base_info.get('Nombre com√∫n', filename)}")

print(f"\nüìÅ Datos guardados en: {output_csv}")
